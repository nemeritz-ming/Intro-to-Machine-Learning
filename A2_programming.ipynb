{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP3670/6670 Programming Assignment 2 - Clustering and Vector Calculus\n",
    "---\n",
    "\n",
    "**Enter Your Student ID:**\n",
    "\n",
    "**Your Name:**\n",
    "    \n",
    "**Deadline:**\n",
    "\n",
    "**Submit:** Write your answers in this file, and submit a single Jupyter Notebook file (.ipynb) on Wattle. Rename this file with your student number as 'uXXXXXXX.ipynb'.\n",
    "\n",
    "**Enter Discussion Partner IDs Below:**\n",
    "You could add more IDs with the same markdown format above.\n",
    "\n",
    "**Programming Section**:\n",
    "- 1.1: 15%\n",
    "- 1.2: 20%\n",
    "- 2.1: 10%\n",
    "- 2.2: 15%\n",
    "- 2.3: 15%\n",
    "- 2.4: 10%\n",
    "- 2.5: 10%\n",
    "- 2.6: 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1: Vector Calculus \n",
    "-----------\n",
    "This part is about vector calculus. In this section, we will use the rigorous definition of the derivative to calculus it.\n",
    "$$ f'(a) = \\lim_{h \\to 0}\\dfrac{f(a + h) - f(a)}{h}$$\n",
    "Now, expand it to vectors.\n",
    "\n",
    "-----\n",
    "**Task 1.1:** Calculate the gradient of $f(\\textbf{x}) = \\textbf{x}^T\\textbf{a}$ respect to $\\textbf{x}$.     $\\textbf{x}, \\textbf{a} \\in \\mathbb{R}^N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "x = np.random.rand(N)\n",
    "a = np.random.rand(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_function1(x, a, N):\n",
    "    # The answer is a vector\n",
    "    # Please follow the rigorous defination of derivative to answer this question\n",
    "    # Directly return the conclusion from textbook will not receive any mark.\n",
    "    \n",
    "    h = 1e-4\n",
    "    # Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "**Task 1.2:** Calculate the gradient of $f(\\textbf{x}) = \\textbf{x}^TB\\textbf{x}$ respect to $\\textbf{x}$.     $\\textbf{x}\\in \\mathbb{R}^N, B\\in \\mathbb{R}^{N\\times N}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(N)\n",
    "B = np.random.rand(N, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_function2(x, B, N):\n",
    "    # The answer is a vector\n",
    "    # Please follow the rigorous defination of derivative to answer this question\n",
    "    # Directly return the conclusion from textbook will not receive any mark.\n",
    "    \n",
    "    h = 1e-5\n",
    "    # Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task2: Clustering\n",
    "-----------\n",
    "These programming exercises will focus on K-means clustering. \n",
    "\n",
    "If you're unsure of how k-means works, read this very helpful and freely available online breakdown from Stanford's CS221 course; https://stanford.edu/~cpiech/cs221/handouts/kmeans.html\n",
    "\n",
    "This assignment requires you to loosely interpret how k-means is a specific case of a more general algorithm named Expectation Maximisation. This is explained toward the end of the above article.\n",
    "\n",
    "First, lets loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"./data.npy\")\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 1000 4-dimensional samples. However, we don't know how many centroids it contains. The number of centroids is more than 5 but less than 10. We need to figure it out in the clustering procedure.\n",
    "\n",
    "-----\n",
    "\n",
    "K-means is a special, simple case of the Expectation Maximisation (EM) algorithm.\n",
    "\n",
    "This simplified EM (k-means), is divided into two steps.\n",
    "\n",
    "The **E-Step**, where for every sample in your dataset you find which \"centroid\" that datapoint is closest to that sample, and record that information.\n",
    "\n",
    "The **M-Step**, where you move each \"centroid\" to the center of the samples which were found to be closest to it in the **E-Step**.\n",
    "\n",
    "Each *centroid* is simply an estimated mean of a cluster. If you have $1$ centroid, then this centroid will become the mean of all your data.\n",
    "\n",
    "If each of your samples, such as the 400 you generated in the previous question, are of dimension $n$, then each of your centroids will be of dimension $n$.\n",
    "\n",
    "Centroids are initially random values, and the k-means algorithm attempts to modify them so that each one represents the center of a cluster.\n",
    "\n",
    "---\n",
    "\n",
    "**TASK 2.1:** Write a function $initialise\\_parameters(m, n, X) = C$ which generates $m$ centroids, each of dimension $n$, and stores them in a matrix $C \\in \\mathbb{R}^{m \\times n}$.\n",
    "\n",
    "No two centroids should be the same, and **must not** be hard coded. Generate these parameters using a sensible initialisation method such as those described in the first link below. You will be judged based on whether the method you choose is sensible and likely to result in kmeans converging to good result.\n",
    "\n",
    "---\n",
    "\n",
    "**HINT:** \n",
    "- https://en.wikipedia.org/wiki/K-means_clustering#Initialization_methods\n",
    "- https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.randint.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_parameters(m, n, X):\n",
    "    C = np.zeros((m,n))\n",
    "    # Your Code Here\n",
    "    return C\n",
    "\n",
    "C = initialise_parameters(2, 4, X)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement k-means.\n",
    "\n",
    "---\n",
    "   **TASK 2.2:** Create a function $E\\_step(C, X) = L$, where $L$ is a matrix of the same dimension of the dataset $X$.\n",
    "   \n",
    "   This function is is the **E-Step** (or \"assignment step\") mentioned earlier.\n",
    "\n",
    "---\n",
    "\n",
    "**HINT:** \n",
    "- https://stanford.edu/~cpiech/cs221/handouts/kmeans.html\n",
    "- https://en.wikipedia.org/wiki/K-means_clustering#Standard_algorithm\n",
    "- Each row of $L$ is a centroid taken from $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_step(C, X):\n",
    "    L = np.zeros(X.shape)\n",
    "    # Your Code Here\n",
    "    return L\n",
    "\n",
    "L = E_step(C, X)\n",
    "plt.scatter(L[:, 0], L[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**TASK 2.3:** Create a function $M\\_step(C, X, L) = C$ which returns $C$ modified so that each centroid in $C$ is placed in the middle of the samples assigned to it. This is the **M-Step**.\n",
    "\n",
    "In other words, make each centroid in $C$ the average of all the samples which were found to be closest to it during the **E-step**. This is also called the \"update step\" for K-means.\n",
    "\n",
    "---\n",
    "\n",
    "**HINT:** https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_equal.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_step(C, X, L):\n",
    "    # Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**TASK 2.4:** Implement $kmeans(X, m, i) = C, L$ which takes a dataset $X$ (of any dimension) and a scalar value $m$, and uses the previous 3 functions you wrote to:\n",
    "- generate $m$ centroids.\n",
    "- iterate between the E and M steps $i$ times (ie, it iterates $i$ times) to classify the $m$ clusters.\n",
    "\n",
    "...and then returns:\n",
    "- $C$, the centers of the $m$ clusters after $i$ iterations.\n",
    "- $L$, the labels (centroid values) assigned to each sample in the dataset after $i$ iterations.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, m, i):\n",
    "    L = np.zeros(X.shape)\n",
    "    C = np.zeros((m, X.shape[1]))\n",
    "    # Your Code Here\n",
    "    return C, L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Task 2.5:** The following code is to display the result. However, due to the limitation of our visualization tools, it can only presents the data in the two dimensional space. While the dimension of the dataset is 4, we really want to visualize the data in the two dimensional figure. Besides, the number of centroids is not determined yet.\n",
    "\n",
    "This task is ask you to modify the following code so as to give the best visualization effect. \n",
    "\n",
    "---\n",
    "**HINT:** You only need to change \"number of centroid\", \"dimension1\", \"dimension2\" to a number, which are quoted by \"#\" in the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = #number of centroid#\n",
    "i = 100\n",
    "#CODE TO DISPLAY YOUR RESULTS.\n",
    "C_final, L_final = kmeans(X, m, i)\n",
    "print('Initial Parameters:')\n",
    "print(C)\n",
    "print('\\nFinal Parameters:')\n",
    "print(C_final)\n",
    "\n",
    "def allocator(X, L, c):\n",
    "    cluster = []\n",
    "    for i in range(L.shape[0]):\n",
    "        if np.array_equal(L[i, :], c):\n",
    "            cluster.append(X[i, :])\n",
    "    return np.asarray(cluster)\n",
    "\n",
    "colours = ['r', 'g', 'b', 'y', 'c', 'm', 'k', 'lime', 'wheat', 'fuchsia', 'pink']\n",
    "for i in range(m):\n",
    "    cluster = allocator(X, L_final, C_final[i, :])\n",
    "    plt.scatter(cluster[:,#dimension1#], \n",
    "                cluster[:,#dimension2#], \n",
    "                c=colours[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**TASK 2.6:** Use your own words to explain how you found the number of centroids in Task 2.5 and how you might do this in the real world.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
